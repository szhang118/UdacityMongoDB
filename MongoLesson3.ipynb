{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#osm_file = open(\"chicago.osm\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
    "street_types = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name) #check if matches regex for street name\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        street_types[street_type] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower()) #sort keys by lowered string\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print \"%s: %d\" % (k, v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\") #check if XML element is street name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit():\n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        if is_street_name(elem):\n",
    "            audit_street_type(street_types, elem.attrib['v'])   \n",
    "    print_sorted_dict(street_types) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensure_float(v):\n",
    "    if is_number(v):\n",
    "        return float(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def audit_population_density(input_file):\n",
    "    for row in input_file:\n",
    "        try:\n",
    "            population = float(row['populationTotal'])\n",
    "            area = float(row['areaLand'])\n",
    "            population_density = float(row['populationDensity'])\n",
    "            calculated_density = population/area\n",
    "            if math.fabs(calculated_density-population_density)>10:\n",
    "                print 'Possibly bad population density for ', row['name']\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possibly bad population density for  Ketchikan Alaska\n"
     ]
    }
   ],
   "source": [
    "input_file = csv.DictReader(open('cities.csv'))\n",
    "input_file.next()\n",
    "input_file.next()\n",
    "input_file.next()\n",
    "audit_population_density(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
    "The following things should be done:\n",
    "- check if the field \"productionStartYear\" contains a year\n",
    "- check if the year is in range 1886-2014\n",
    "- convert the value of the field to be just a year (not full datetime)\n",
    "- the rest of the fields and values should stay the same\n",
    "- if the value of the field is a valid year in range, as described above,\n",
    "  write that line to the output_good file\n",
    "- if the value of the field is not a valid year, \n",
    "  write that line to the output_bad file\n",
    "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
    "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
    "  They will take care of dealing with the header.\n",
    "\n",
    "You can write helper functions for checking the data and writing the files, but we will call only the \n",
    "'process_file' with 3 arguments (inputfile, output_good, output_bad).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_file(input_file, output_good, output_bad):\n",
    "    good_data = []\n",
    "    bad_data = []\n",
    "    with open(input_file, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "        for row in reader:\n",
    "            #validate URI value\n",
    "            if row['URI'].find('dbpedia.org') < 0:\n",
    "                continue #exclude data if not proper URI\n",
    "            pyear = row['productionStartYear']\n",
    "            try:\n",
    "                year = int(pyear[:4])\n",
    "                if year>=1886 and year<=2014: #check if year is in the specified range\n",
    "                    row['productionStartYear'] = year\n",
    "                    good_data.append(row)\n",
    "                else: \n",
    "                    bad_data.append(row)\n",
    "            except:\n",
    "                bad_data.append(row)        \n",
    "\n",
    "    #write good output and bad output to csv files\n",
    "    with open(output_good, \"w\") as g:\n",
    "        writer = csv.DictWriter(g, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in good_data:\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    with open(output_bad, 'w') as b:\n",
    "        writer = csv.DictWriter(b, delimiter=',', fieldnames=header)\n",
    "        writer.writeheader()\n",
    "        for row in bad_data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_file('autos.csv', 'goodautos.csv', 'badautos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def skip_lines(input_file, skip): #skip lines in a csv file reader\n",
    "    for i in range(0, skip):\n",
    "        next(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_array(s):\n",
    "    if ('{' in s) or ('[' in s):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fieldname = 'wgs84_pos#lat'\n",
    "minval = -90\n",
    "maxval = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_float_field(v, counts):\n",
    "    v = v.strip()\n",
    "    if v == \"NULL\":\n",
    "        counts['nulls'] += 1\n",
    "    elif v == '':\n",
    "        counts['empties'] += 1\n",
    "    elif is_array(v):\n",
    "        counts['arrays'] += 1\n",
    "    elif not is_number(v):\n",
    "        print 'Found non number:', v\n",
    "    else:\n",
    "        v = float(v)\n",
    "        if not ((minval<v) and (v<maxval)):\n",
    "            print 'Found out of range value:', v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found out of range value: 200.0\n",
      "Number of cities: 39\n",
      "Nulls: 0\n",
      "Empties: 2\n",
      "Numbr of arrays: 1\n"
     ]
    }
   ],
   "source": [
    "input_file = csv.DictReader(open('cities.csv'))\n",
    "skip_lines(input_file, 3)\n",
    "counts = {'nulls':0, 'empties':0, 'arrays':0}\n",
    "nrows = 0\n",
    "for row in input_file:\n",
    "    audit_float_field(row[fieldname], counts)\n",
    "    nrows += 1\n",
    "print 'Number of cities:', nrows\n",
    "print 'Nulls:', counts['nulls']\n",
    "print 'Empties:', counts['empties']\n",
    "print 'Numbr of arrays:', counts['arrays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIELDS = [\"name\", \"timeZone_label\", \"utcOffset\", \"homepage\", \"governmentType_label\",\n",
    "          \"isPartOf_label\", \"areaCode\", \"populationTotal\", \"elevation\",\n",
    "          \"maximumElevation\", \"minimumElevation\", \"populationDensity\",\n",
    "          \"wgs84_pos#lat\", \"wgs84_pos#long\", \"areaLand\", \"areaMetro\", \"areaUrban\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def audit_file(filename, fields):\n",
    "    fieldtypes = {f:set([]) for f in fields}\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        skip_lines(reader, 3)\n",
    "        for row in reader:\n",
    "            for field in FIELDS:\n",
    "                if row[field] == 'NULL' or row[field] == '':\n",
    "                    fieldtypes[field].add(type(None))\n",
    "                elif is_array(row[field]):\n",
    "                    fieldtypes[field].add(type([]))\n",
    "                elif is_number(row[field]):\n",
    "                    try:\n",
    "                        int(row[field])\n",
    "                        fieldtypes[field].add(type(1))\n",
    "                    except:\n",
    "                        fieldtypes[field].add(type(1.1))\n",
    "                else:\n",
    "                    fieldtypes[field].add(type('fart'))\n",
    "    return fieldtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'areaCode': {int, NoneType, str},\n",
       " 'areaLand': {float, list, NoneType},\n",
       " 'areaMetro': {float, NoneType},\n",
       " 'areaUrban': {float, NoneType},\n",
       " 'elevation': {int, list, NoneType},\n",
       " 'governmentType_label': {NoneType, str},\n",
       " 'homepage': {NoneType, str},\n",
       " 'isPartOf_label': {list, NoneType, str},\n",
       " 'maximumElevation': {NoneType},\n",
       " 'minimumElevation': {NoneType},\n",
       " 'name': {list, NoneType, str},\n",
       " 'populationDensity': {float, list, NoneType},\n",
       " 'populationTotal': {int, NoneType},\n",
       " 'timeZone_label': {NoneType, str},\n",
       " 'utcOffset': {int, list, NoneType, str},\n",
       " 'wgs84_pos#lat': {float, int, list, NoneType, str},\n",
       " 'wgs84_pos#long': {float}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = audit_file('cities.csv', FIELDS)\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_area(area):\n",
    "    \"\"\"\n",
    "    Finish the function fix_area(). It will receive a string as an input, and it\n",
    "    has to return a float representing the value of the area or None.\n",
    "    You have to change the function fix_area. You can use extra functions if you\n",
    "    like, but changes to process_file will not be taken into account.\n",
    "    The rest of the code is just an example on how this function can be used.\n",
    "    \"\"\"\n",
    "    if area == 'NULL' or area == '':\n",
    "        return None\n",
    "    elif area[0] == '{':\n",
    "        if '|' in area:\n",
    "            areas = area[1:-1].split('|')\n",
    "            if len(areas[0]) > len(areas[1]):\n",
    "                return float(areas[0])\n",
    "            else:\n",
    "                return float(areas[1])\n",
    "    return float(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_area(filename, fieldname):\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        #skipping the extra metadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            # calling your function to fix the area value\n",
    "            if fieldname in line:\n",
    "                line[fieldname] = fix_area(line[fieldname])\n",
    "            data.append(line[fieldname])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 7070000000.0, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print process_area('cities.csv', 'areaMetro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_name(name):\n",
    "    \"\"\"\n",
    "    In the previous quiz you recognized that the \"name\" value can be an array (or\n",
    "    list in Python terms). It would make it easier to process and query the data\n",
    "    later if all values for the name are in a Python list, instead of being\n",
    "    just a string separated with special characters, like now.\n",
    "\n",
    "    Finish the function fix_name(). It will recieve a string as an input, and it\n",
    "    will return a list of all the names. If there is only one name, the list will\n",
    "    have only one item in it; if the name is \"NULL\", the list should be empty.\n",
    "    The rest of the code is just an example on how this function can be used.\n",
    "    \"\"\"\n",
    "    fixed = []\n",
    "    if name == 'NULL' or type(name) == type(None):\n",
    "        return fixed\n",
    "    elif '{' in name:\n",
    "        split_names = name[1:-1].split('|')\n",
    "        for s in split_names:\n",
    "            fixed.append(s)\n",
    "        return fixed\n",
    "    return [name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_loc(point, lat, longi):    \n",
    "    \"\"\"\n",
    "    Finish the function check_loc(). It will recieve 3 strings: first, the combined\n",
    "    value of \"point\" followed by the separate \"wgs84_pos#\" values. You have to\n",
    "    extract the lat and long values from the \"point\" argument and compare them to\n",
    "    the \"wgs84_pos# values, returning True or False.\"\"\"\n",
    "    point_lat = point.split(\" \")[0]\n",
    "    point_long = point.split(\" \")[1]\n",
    "    return (point_lat == lat) and (point_long == longi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_latlong(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        #skipping the extra matadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            # calling your function to check the location\n",
    "            result = check_loc(line[\"point\"], line[\"wgs84_pos#lat\"], line[\"wgs84_pos#long\"])\n",
    "            if not result:\n",
    "                print \"{}: {} != {} {}\".format(line[\"name\"], line[\"point\"], line[\"wgs84_pos#lat\"], line[\"wgs84_pos#long\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
